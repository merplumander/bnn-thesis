{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "from data.toy_regression import create_linear_data, ground_truth_linear_function\n",
    "from core.preprocessing import preprocess_create_x_train_test\n",
    "from core.network_utils import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [1]\n",
    "layer_units = [2]\n",
    "layer_activations = [\"linear\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 20\n",
    "_x_train, y_train = create_linear_data(n_train, m=3, b=1, sigma=1)\n",
    "x_train, _x_test, x_test = preprocess_create_x_train_test(_x_train)\n",
    "y_test = ground_truth_linear_function(_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([1, 0]).reshape(1, -1)\n",
    "b = np.zeros((2)) \n",
    "b[1] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_log_prob_fn(wb):\n",
    "    print(wb)\n",
    "    _w = np.expand_dims(wb[0, 0])#tf.reshape(tf.stack((w, tf.constant(0., dtype='float32')), axis=0), (1, -1))\n",
    "    _b = wb[0, 1]\n",
    "    print(_w.shape)\n",
    "    net = tf.matmul(_x_train, _w) + _b\n",
    "    y_pred, y_unconstrained_std = tf.unstack(net, axis=1)\n",
    "    prediction = tfp.distributions.Normal(loc=y_pred, scale=1e-6 + tf.math.softplus(0.05 * y_unconstrained_std))\n",
    "    return tf.reduce_sum(prediction.log_prob(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = np.array([[1, 1], [0, 0]]).reshape((1,) + (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1. 1.]\n",
      "  [0. 0.]]], shape=(1, 2, 2), dtype=float32)\n",
      "(2,)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "In[1] is not a matrix. Instead it has shape [2] [Op:MatMul] name: mcmc_sample_chain/dual_averaging_step_size_adaptation___init__/_bootstrap_results/mh_bootstrap_results/hmc_kernel_bootstrap_results/maybe_call_fn_and_grads/value_and_gradients/MatMul/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-e1036315c7dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_accepted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_accepted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0msample_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0msample_stddev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-e1036315c7dd>\u001b[0m in \u001b[0;36mrun_chain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m       \u001b[0mcurrent_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madaptive_kernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m       trace_fn=lambda _, pkr: pkr.inner_results.is_accepted)\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_accepted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Academia/University_of_Tübingen/Thesis/Code/.venv_thesis/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/sample.py\u001b[0m in \u001b[0;36msample_chain\u001b[0;34m(num_results, current_state, previous_kernel_results, kernel, num_burnin_steps, num_steps_between_results, trace_fn, return_final_kernel_results, parallel_iterations, name)\u001b[0m\n\u001b[1;32m    322\u001b[0m         current_state)\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprevious_kernel_results\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0mprevious_kernel_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbootstrap_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrace_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Academia/University_of_Tübingen/Thesis/Code/.venv_thesis/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/dual_averaging_step_size_adaptation.py\u001b[0m in \u001b[0;36mbootstrap_results\u001b[0;34m(self, init_state)\u001b[0m\n\u001b[1;32m    483\u001b[0m         mcmc_util.make_name(self.name, 'dual_averaging_step_size_adaptation',\n\u001b[1;32m    484\u001b[0m                             'bootstrap_results')):\n\u001b[0;32m--> 485\u001b[0;31m       \u001b[0minner_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_kernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbootstrap_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m       \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_size_getter_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Academia/University_of_Tübingen/Thesis/Code/.venv_thesis/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/hmc.py\u001b[0m in \u001b[0;36mbootstrap_results\u001b[0;34m(self, init_state)\u001b[0m\n\u001b[1;32m    556\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbootstrap_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0;34m\"\"\"Creates initial `previous_kernel_results` using a supplied `state`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m     \u001b[0mkernel_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbootstrap_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_size_update_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m       \u001b[0mstep_size_assign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_size_update_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Academia/University_of_Tübingen/Thesis/Code/.venv_thesis/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/metropolis_hastings.py\u001b[0m in \u001b[0;36mbootstrap_results\u001b[0;34m(self, init_state)\u001b[0m\n\u001b[1;32m    262\u001b[0m     with tf.name_scope(mcmc_util.make_name(\n\u001b[1;32m    263\u001b[0m         self.name, 'mh', 'bootstrap_results')):\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0mpkr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_kernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbootstrap_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_target_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/Documents/Academia/University_of_Tübingen/Thesis/Code/.venv_thesis/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/hmc.py\u001b[0m in \u001b[0;36mbootstrap_results\u001b[0;34m(self, init_state)\u001b[0m\n\u001b[1;32m    763\u001b[0m           \u001b[0minit_target_log_prob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m           \u001b[0minit_grads_target_log_prob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m       ] = mcmc_util.maybe_call_fn_and_grads(self.target_log_prob_fn, init_state)\n\u001b[0m\u001b[1;32m    766\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_store_parameters_in_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         return UncalibratedHamiltonianMonteCarloKernelResults(\n",
      "\u001b[0;32m~/Documents/Academia/University_of_Tübingen/Thesis/Code/.venv_thesis/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36mmaybe_call_fn_and_grads\u001b[0;34m(fn, fn_arg_list, result, grads, check_non_none_grads, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m     fn_arg_list = (list(fn_arg_list) if is_list_like(fn_arg_list)\n\u001b[1;32m    264\u001b[0m                    else [fn_arg_list])\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_value_and_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_arg_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     if not all(dtype_util.is_floating(r.dtype)\n\u001b[1;32m    267\u001b[0m                for r in (result if is_list_like(result) else [result])):  # pylint: disable=superfluous-parens\n",
      "\u001b[0;32m~/Documents/Academia/University_of_Tübingen/Thesis/Code/.venv_thesis/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36m_value_and_gradients\u001b[0;34m(fn, fn_arg_list, result, grads, name)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_arg_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m# Ensure we disable bijector cacheing in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-9523816fecbe>\u001b[0m in \u001b[0;36mtarget_log_prob_fn\u001b[0;34m(wb)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0m_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_x_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_unconstrained_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftplus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.05\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_unconstrained_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Academia/University_of_Tübingen/Thesis/Code/.venv_thesis/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Academia/University_of_Tübingen/Thesis/Code/.venv_thesis/lib/python3.6/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2796\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2797\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[0;32m-> 2798\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   2799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Academia/University_of_Tübingen/Thesis/Code/.venv_thesis/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5614\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5615\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5616\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5617\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5618\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtranspose_a\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Academia/University_of_Tübingen/Thesis/Code/.venv_thesis/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6605\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6606\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6607\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Academia/University_of_Tübingen/Thesis/Code/.venv_thesis/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: In[1] is not a matrix. Instead it has shape [2] [Op:MatMul] name: mcmc_sample_chain/dual_averaging_step_size_adaptation___init__/_bootstrap_results/mh_bootstrap_results/hmc_kernel_bootstrap_results/maybe_call_fn_and_grads/value_and_gradients/MatMul/"
     ]
    }
   ],
   "source": [
    "# model = build_model(input_shape, layer_units, layer_activations)\n",
    "# def target_log_prob_fn(x):\n",
    "#     print(x)\n",
    "#     x = tf.reshape(x, (1, 1))\n",
    "#     ls = model(x)\n",
    "#     l = ls[0, 0]\n",
    "#     s = ls[0, 1]\n",
    "#     return tf.reduce_sum(tfd.Normal(loc=l, scale=1.).log_prob(np.ones(5)))\n",
    "\n",
    "# Initialize the HMC transition kernel.\n",
    "initial_state = np.array([[1, 1], [0, 0]], dtype='float32')\n",
    "initial_state = initial_state.reshape((1, ) + initial_state.shape)\n",
    "num_results = int(1e2)\n",
    "num_burnin_steps = int(30)\n",
    "step_size = 1.\n",
    "num_leapfrog_steps = 2\n",
    "step_size_adapter = \"dual_averaging\"\n",
    "sampler = \"hmc\"\n",
    "\n",
    "step_size_adapter = {\n",
    "    \"simple\": tfp.mcmc.SimpleStepSizeAdaptation,\n",
    "    \"dual_averaging\": tfp.mcmc.DualAveragingStepSizeAdaptation,\n",
    "}[step_size_adapter]\n",
    "if sampler == \"nuts\":\n",
    "    kernel = tfp.mcmc.NoUTurnSampler(target_log_prob_fn, step_size=step_size)\n",
    "    adaptive_kernel = step_size_adapter(\n",
    "        kernel,\n",
    "        num_adaptation_steps=int(num_burnin_steps * 0.8),\n",
    "        step_size_setter_fn=lambda pkr, new_step_size: pkr._replace(\n",
    "            step_size=new_step_size\n",
    "        ),\n",
    "        step_size_getter_fn=lambda pkr: pkr.step_size,\n",
    "        log_accept_prob_getter_fn=lambda pkr: pkr.log_accept_ratio,\n",
    "    )\n",
    "elif sampler == \"hmc\":\n",
    "    kernel = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "        target_log_prob_fn,\n",
    "        step_size=step_size,\n",
    "        num_leapfrog_steps=num_leapfrog_steps,\n",
    "    )\n",
    "    adaptive_kernel = step_size_adapter(\n",
    "        kernel, num_adaptation_steps=int(num_burnin_steps * 0.8),\n",
    "    )\n",
    "\n",
    "# Run the chain (with burn-in).\n",
    "#@tf.function\n",
    "def run_chain():\n",
    "  # Run the chain (with burn-in).\n",
    "    samples, is_accepted = tfp.mcmc.sample_chain(\n",
    "      num_results=num_results,\n",
    "      num_burnin_steps=num_burnin_steps,\n",
    "      current_state=initial_state,\n",
    "      kernel=adaptive_kernel,\n",
    "      trace_fn=lambda _, pkr: pkr.inner_results.is_accepted)\n",
    "\n",
    "    return samples, is_accepted\n",
    "\n",
    "samples, is_accepted = run_chain()\n",
    "sample_mean = tf.reduce_mean(samples)\n",
    "sample_stddev = tf.math.reduce_std(samples)\n",
    "is_accepted = tf.reduce_mean(tf.cast(is_accepted, dtype=tf.float32))\n",
    "\n",
    "print('mean:{:.4f}  stddev:{:.4f}  acceptance:{:.4f}'.format(\n",
    "    sample_mean.numpy(), sample_stddev.numpy(), is_accepted.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 1, 2), dtype=float32, numpy=\n",
       "array([[[0.15731606, 1.7696476 ]],\n",
       "\n",
       "       [[0.13462949, 1.8311614 ]],\n",
       "\n",
       "       [[0.10783669, 1.8606288 ]],\n",
       "\n",
       "       [[0.10783669, 1.8606288 ]],\n",
       "\n",
       "       [[0.10610261, 1.8693013 ]],\n",
       "\n",
       "       [[0.12161877, 1.7428343 ]],\n",
       "\n",
       "       [[0.08214192, 1.7536923 ]],\n",
       "\n",
       "       [[0.13221863, 1.6996726 ]],\n",
       "\n",
       "       [[0.11793502, 1.6624676 ]],\n",
       "\n",
       "       [[0.13173181, 1.6960788 ]],\n",
       "\n",
       "       [[0.11650054, 1.7869112 ]],\n",
       "\n",
       "       [[0.10637537, 1.7492055 ]],\n",
       "\n",
       "       [[0.12507032, 1.7743533 ]],\n",
       "\n",
       "       [[0.08862688, 1.7211844 ]],\n",
       "\n",
       "       [[0.15290585, 1.658581  ]],\n",
       "\n",
       "       [[0.11831407, 1.6270393 ]],\n",
       "\n",
       "       [[0.15279323, 1.6760348 ]],\n",
       "\n",
       "       [[0.10023018, 1.7907156 ]],\n",
       "\n",
       "       [[0.12068367, 1.8609116 ]],\n",
       "\n",
       "       [[0.1027743 , 1.9342159 ]],\n",
       "\n",
       "       [[0.06719038, 1.9506385 ]],\n",
       "\n",
       "       [[0.10886997, 1.895876  ]],\n",
       "\n",
       "       [[0.09780123, 1.9167316 ]],\n",
       "\n",
       "       [[0.08841945, 1.7928467 ]],\n",
       "\n",
       "       [[0.11299814, 1.7922671 ]],\n",
       "\n",
       "       [[0.10827324, 1.8181018 ]],\n",
       "\n",
       "       [[0.08178465, 1.814771  ]],\n",
       "\n",
       "       [[0.08178465, 1.814771  ]],\n",
       "\n",
       "       [[0.06986349, 1.8513652 ]],\n",
       "\n",
       "       [[0.0476272 , 1.9232867 ]],\n",
       "\n",
       "       [[0.13346055, 2.0429072 ]],\n",
       "\n",
       "       [[0.03975832, 2.0260658 ]],\n",
       "\n",
       "       [[0.09243758, 1.9922862 ]],\n",
       "\n",
       "       [[0.11172064, 2.0183237 ]],\n",
       "\n",
       "       [[0.13764708, 1.9311446 ]],\n",
       "\n",
       "       [[0.1122992 , 1.9123385 ]],\n",
       "\n",
       "       [[0.14991568, 1.8818376 ]],\n",
       "\n",
       "       [[0.07071139, 1.8505318 ]],\n",
       "\n",
       "       [[0.08309844, 1.7837038 ]],\n",
       "\n",
       "       [[0.11211672, 1.8028811 ]],\n",
       "\n",
       "       [[0.07931454, 1.8588988 ]],\n",
       "\n",
       "       [[0.16159043, 1.8964974 ]],\n",
       "\n",
       "       [[0.06580964, 1.9210199 ]],\n",
       "\n",
       "       [[0.08791545, 1.9047483 ]],\n",
       "\n",
       "       [[0.07461177, 1.8714861 ]],\n",
       "\n",
       "       [[0.07461177, 1.8714861 ]],\n",
       "\n",
       "       [[0.05125636, 1.8399552 ]],\n",
       "\n",
       "       [[0.05983074, 1.7929388 ]],\n",
       "\n",
       "       [[0.11801271, 1.795886  ]],\n",
       "\n",
       "       [[0.11914881, 1.8100321 ]],\n",
       "\n",
       "       [[0.02933316, 1.8468908 ]],\n",
       "\n",
       "       [[0.14443904, 1.9682977 ]],\n",
       "\n",
       "       [[0.09946579, 1.928831  ]],\n",
       "\n",
       "       [[0.05053752, 1.851079  ]],\n",
       "\n",
       "       [[0.10194223, 1.8997613 ]],\n",
       "\n",
       "       [[0.08534757, 1.8443079 ]],\n",
       "\n",
       "       [[0.14139839, 1.8184193 ]],\n",
       "\n",
       "       [[0.05545827, 1.850753  ]],\n",
       "\n",
       "       [[0.10279712, 1.8249434 ]],\n",
       "\n",
       "       [[0.09349463, 1.9132247 ]],\n",
       "\n",
       "       [[0.05504079, 1.9825118 ]],\n",
       "\n",
       "       [[0.05504079, 1.9825118 ]],\n",
       "\n",
       "       [[0.11059897, 2.0414999 ]],\n",
       "\n",
       "       [[0.03972138, 2.0598342 ]],\n",
       "\n",
       "       [[0.12831968, 2.0198681 ]],\n",
       "\n",
       "       [[0.04551131, 2.0677347 ]],\n",
       "\n",
       "       [[0.01240676, 2.089594  ]],\n",
       "\n",
       "       [[0.07485825, 2.091575  ]],\n",
       "\n",
       "       [[0.10340916, 2.1149454 ]],\n",
       "\n",
       "       [[0.03892047, 2.086848  ]],\n",
       "\n",
       "       [[0.09304961, 2.1842773 ]],\n",
       "\n",
       "       [[0.11366685, 2.140392  ]],\n",
       "\n",
       "       [[0.03554046, 2.1097536 ]],\n",
       "\n",
       "       [[0.065911  , 2.1222174 ]],\n",
       "\n",
       "       [[0.05758871, 2.0503774 ]],\n",
       "\n",
       "       [[0.06186112, 1.9708902 ]],\n",
       "\n",
       "       [[0.05430053, 1.9616534 ]],\n",
       "\n",
       "       [[0.09466618, 2.0174992 ]],\n",
       "\n",
       "       [[0.08424491, 1.9374841 ]],\n",
       "\n",
       "       [[0.08114833, 1.9253203 ]],\n",
       "\n",
       "       [[0.06871173, 1.7984155 ]],\n",
       "\n",
       "       [[0.06871173, 1.7984155 ]],\n",
       "\n",
       "       [[0.15081549, 1.8345088 ]],\n",
       "\n",
       "       [[0.07801269, 1.8337476 ]],\n",
       "\n",
       "       [[0.12729375, 1.8498834 ]],\n",
       "\n",
       "       [[0.09770516, 1.8682307 ]],\n",
       "\n",
       "       [[0.09770516, 1.8682307 ]],\n",
       "\n",
       "       [[0.097441  , 1.975618  ]],\n",
       "\n",
       "       [[0.09686528, 1.9644465 ]],\n",
       "\n",
       "       [[0.07897132, 1.9824328 ]],\n",
       "\n",
       "       [[0.10391312, 1.9009517 ]],\n",
       "\n",
       "       [[0.13397878, 1.865361  ]],\n",
       "\n",
       "       [[0.08144917, 1.8649906 ]],\n",
       "\n",
       "       [[0.08755733, 1.8628368 ]],\n",
       "\n",
       "       [[0.08533362, 1.9340645 ]],\n",
       "\n",
       "       [[0.09798662, 1.8842292 ]],\n",
       "\n",
       "       [[0.10245875, 1.8996594 ]],\n",
       "\n",
       "       [[0.07918426, 1.8795972 ]],\n",
       "\n",
       "       [[0.06366321, 1.8652102 ]],\n",
       "\n",
       "       [[0.06612431, 1.8565884 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n",
       "array([[-3.6336331 , -5.605876  ],\n",
       "       [-2.9069066 , -4.4847007 ],\n",
       "       [-2.18018   , -3.3635254 ],\n",
       "       [-1.4534533 , -2.2423503 ],\n",
       "       [-0.72672665, -1.1211752 ],\n",
       "       [ 0.        ,  0.        ],\n",
       "       [ 0.72672665,  1.1211752 ],\n",
       "       [ 1.4534533 ,  2.2423503 ],\n",
       "       [ 2.18018   ,  3.3635254 ],\n",
       "       [ 2.9069066 ,  4.4847007 ]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model((np.arange(10)-5).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=float32, numpy=\n",
       "array([ 2.3257124 , -0.20577645,  0.19978791,  0.03424105, -0.08349824,\n",
       "        1.5081794 ,  1.4159038 ,  2.0308464 , -0.10871029,  0.28580248,\n",
       "        0.902448  ,  0.07596786,  1.2128446 ,  0.887585  ,  1.4048815 ,\n",
       "        1.5153879 , -1.7769922 ,  0.6979221 ,  0.09650894,  0.20094928,\n",
       "        1.7372818 ,  0.72853154,  0.3511223 ,  0.8152547 ,  3.8389397 ,\n",
       "        1.5429881 ,  1.8295449 ,  1.4188477 ,  3.4186873 ,  0.35176575,\n",
       "        1.4801888 ,  0.9883277 ,  0.7906201 ,  0.15862834, -1.1441915 ,\n",
       "        1.921804  ,  1.2293398 ,  1.7564956 ,  1.8990531 , -0.4522009 ,\n",
       "       -0.3013208 ,  1.9032283 ,  1.4277234 , -0.84536034,  2.0777595 ,\n",
       "       -1.0363597 , -0.37081444, -0.56208473,  1.3032736 ,  1.5694382 ,\n",
       "        0.920076  ,  1.8546269 , -0.24779195, -0.24779195,  1.9183695 ,\n",
       "        0.20211214,  0.36986756,  1.3416731 ,  1.0556343 ,  1.5287949 ,\n",
       "        1.6589696 ,  0.8491319 ,  0.07071872,  0.7900215 , -0.07740676,\n",
       "       -0.07740676,  2.4839766 ,  1.4894934 ,  1.0319605 , -0.11662924,\n",
       "        0.14579451, -0.4040504 ,  1.8149602 ,  0.13283318,  1.6984036 ,\n",
       "        0.40109944,  0.23621786,  1.2859908 , -1.2219532 ,  1.0673642 ,\n",
       "        1.5142635 ,  0.47062165, -0.14539802, -0.2052095 ,  1.0143747 ,\n",
       "        2.0765579 ,  1.2215221 ,  2.170504  , -0.43519115,  2.805998  ,\n",
       "        2.8990192 ,  0.09341741,  2.5251822 ,  2.5251822 , -0.2346071 ,\n",
       "        0.6984834 , -0.15864518,  1.1660837 ,  1.3096713 ,  1.3421352 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
