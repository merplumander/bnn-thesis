{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from data.toy_regression import create_split_periodic_data, ground_truth_periodic_function\n",
    "from core import MapEnsemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are not using gpu, so we might as well use float64 by default as does numpy\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "assert tf.executing_eagerly()\n",
    "\n",
    "figure_dir = './figures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "n_networks = 5\n",
    "n_train = 20\n",
    "batchsize_train = 20\n",
    "\n",
    "_x_train, y_train = create_split_periodic_data(n_train=n_train)\n",
    "x_min, x_max = np.min(_x_train), np.max(_x_train)\n",
    "d = x_max - x_min\n",
    "lower_bound = x_min - d / 2\n",
    "upper_bound = x_max + d / 2\n",
    "\n",
    "scaler = preprocessing.StandardScaler(with_mean=True, with_std=True).fit(_x_train)\n",
    "# we can use _x_train for plotting and x_train for training\n",
    "x_train = scaler.transform(_x_train)\n",
    "\n",
    "_x_test = np.linspace(lower_bound, upper_bound, 500).reshape(-1, 1)\n",
    "y_test = ground_truth_periodic_function(_x_test)\n",
    "x_test = scaler.transform(_x_test)\n",
    "\n",
    "layer_units = [500] * 4 + [1]\n",
    "layer_activations = [\"relu\"] * 4 + [\"linear\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(_x_test, y_test, label=\"Ground truth\", alpha=0.3)\n",
    "ax.scatter(_x_train, y_train, label=\"Train data\")\n",
    "ax.set_xlabel(\"\");\n",
    "ax.set_ylabel(\"\");\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = MapEnsemble(n_networks=n_networks,\n",
    "                       input_shape=[1],\n",
    "                       layer_units=layer_units,\n",
    "                       layer_activations=layer_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.train(x_train=x_train, y_train=y_train, batchsize_train=batchsize_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ensemble.predict(x_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.plot(_x_test, y_test, label=\"Ground truth\", alpha=0.1)\n",
    "for i, prediction in enumerate(predictions):\n",
    "    ax.plot(_x_test, prediction, label=f\"Model {i+1} prediction\", alpha=0.8)\n",
    "ax.scatter(_x_train, y_train, c='k', marker='x', s=100, label=\"Train data\")\n",
    "ax.set_xlabel(\"\");\n",
    "ax.set_ylabel(\"\");\n",
    "ax.set_ylim([-5, 5])\n",
    "ax.legend();\n",
    "#fig.savefig(os.path.join(figure_dir, f\"{n_networks}_ml_ensemble.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
